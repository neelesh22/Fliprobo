{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.1 Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Companies</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MIS/ Data Analyst-(SQL,Automation,Excel/PowerB...</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - SAP</td>\n",
       "      <td>Boston Scientific Corporation</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Pune, Delhi, Bengaluru, Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Schneider Electric</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Security Data Analyst</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  MIS/ Data Analyst-(SQL,Automation,Excel/PowerB...   \n",
       "1                                 Data Analyst - SAP   \n",
       "2                                Senior Data Analyst   \n",
       "3                              Security Data Analyst   \n",
       "\n",
       "                           Companies Experience  \\\n",
       "0  Flipkart Internet Private Limited    1-4 Yrs   \n",
       "1      Boston Scientific Corporation    3-5 Yrs   \n",
       "2                 Schneider Electric    2-5 Yrs   \n",
       "3              Philips India Limited    2-4 Yrs   \n",
       "\n",
       "                          Location  \n",
       "0                        Bengaluru  \n",
       "1  Pune, Delhi, Bengaluru, Gurgaon  \n",
       "2            Bengaluru / Bangalore  \n",
       "3                        Bengaluru  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "search_jobs=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_jobs.send_keys(\"Data Analyst\")\n",
    "search_loc=driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "search_btn=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_btn.click()\n",
    "\n",
    "url=\"https://www.naukri.com/data-analyst-jobs-in-bangalore?k=data%20analyst&l=bangalore\"\n",
    "driver.get(url)\n",
    "\n",
    "job_titles=[]\n",
    "company_name=[]\n",
    "location_list=[]\n",
    "experience_list=[]\n",
    "\n",
    "titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_titles.append(title)\n",
    "    \n",
    "job_titles[:4]\n",
    "\n",
    "companies_tags=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in companies_tags:\n",
    "    companies=i.text\n",
    "    company_name.append(companies)\n",
    "    \n",
    "company_name[:4]\n",
    "\n",
    "location_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span[1]')\n",
    "for i in location_tags:\n",
    "    location=i.text\n",
    "    location_list.append(location)\n",
    "    \n",
    "location_list[:4]\n",
    "\n",
    "experience_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span[1]')\n",
    "for i in experience_tags:\n",
    "    experience=i.text\n",
    "    experience_list.append(experience)\n",
    "    \n",
    "experience_list[:4]\n",
    "\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job_titles\n",
    "jobs['Companies']=company_name\n",
    "jobs['Experience']=experience_list\n",
    "jobs['Location']=location_list\n",
    "\n",
    "jobs[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title   Experience  \\\n",
      "0                           Adv Data Scientist - CSP  2 - 5 years   \n",
      "1  Only Fresher / Data Scientist /  Data Analyst ...      0 years   \n",
      "2                     Data Scientist (Python|Hadoop)  3 - 5 years   \n",
      "3  Data Scientist - SAAS Group ( B2B) - Work From...  5 - 9 years   \n",
      "4  Data Scientist - SAAS Group (B2B) - Work From ...  5 - 9 years   \n",
      "5                                     Data Scientist  3 - 6 years   \n",
      "6                                     Data Scientist  4 - 9 years   \n",
      "7           Data Scientist - Python/Machine Learning  5 - 8 years   \n",
      "8         Machine Learning Engineer / Data Scientist  3 - 7 years   \n",
      "9          Machine Learning Engineer/ Data Scientist  3 - 6 years   \n",
      "\n",
      "                           Company  \\\n",
      "0                      MatrikonOPC   \n",
      "1       GABA Consultancy services    \n",
      "2                            Jubna   \n",
      "3                     Expro Search   \n",
      "4  Vital Bridge Consulting Pvt Ltd   \n",
      "5  Bigshyft Hiring for PayMe India   \n",
      "6          Mailkit Private Limited   \n",
      "7                            Jubna   \n",
      "8                       Durr India   \n",
      "9                          D rr AG   \n",
      "\n",
      "                                         Description  \n",
      "0     As a Sr. Data Engineer, you will be part of...  \n",
      "1  Only Fresher Can Apply:Description1>MS Office ...  \n",
      "2  Roles and Responsibilities• Take ownership of ...  \n",
      "3  Roles and ResponsibilitiesResearch and develop...  \n",
      "4  Roles and Responsibilities  Research and devel...  \n",
      "5  What You'll Do :Design data modeling processes...  \n",
      "6  Mailkit is an European Marketing Automation co...  \n",
      "7  Roles and ResponsibilitiesAs a Data Scientist,...  \n",
      "8       Your Tasks      Validate requirements, ex...  \n",
      "9   Your Tasks     Validate requirements, execute...  \n"
     ]
    }
   ],
   "source": [
    "#importing Libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "# Function Definition\n",
    "def naukri(url):\n",
    "    driver=webdriver.Chrome()\n",
    "    urls = []\n",
    "    title=[]\n",
    "    exp=[]\n",
    "    description=[]\n",
    "    company_name=[]\n",
    "    driver.get(url)\n",
    "    soup= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    prod_urls = soup.find_all('a', attrs ={'class':'title fw500 ellipsis'})\n",
    "    for prod in prod_urls:\n",
    "        urls.append(prod.get('href'))\n",
    "    \n",
    "    #loop to scrap required details\n",
    "    for url in urls:\n",
    "        driver.get(url)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        n = soup.find('h1',attrs={'class':'jd-header-title'})\n",
    "        if n is not None:\n",
    "            title.append(n.text.replace('\\n',''))\n",
    "        else:\n",
    "            title.append('-')\n",
    "        cmp = soup.find('a', attrs = {'class':'pad-rt-8'})\n",
    "        if cmp is not None:\n",
    "            company_name.append(cmp.text)\n",
    "        else:\n",
    "            company_name.append('-')\n",
    "        ex = soup.find('div', attrs = {'class':'exp'})\n",
    "        if ex is not None:\n",
    "            exp.append(ex.span.text)\n",
    "        else:\n",
    "            exp.append('-')\n",
    "            \n",
    "        des = soup.find('div', attrs = {'class':'dang-inner-html'})\n",
    "        if des is not None:\n",
    "            description.append(des.text)\n",
    "        else:\n",
    "            description.append('-')\n",
    "            \n",
    "    mob_df = df=pd.DataFrame({'Title':title,\n",
    "                              'Experience':exp,\n",
    "                              'Company':company_name,\n",
    "                              'Description':description})\n",
    "    print(mob_df[:10])\n",
    "    \n",
    "    \n",
    "# Calling Function\n",
    "naukri('https://www.naukri.com/data-scientist-jobs-in-noida?k=data%20scientist&l=noida')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.3: In this question you have to scrape data using the filters available on naukri.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "search_jobs=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_jobs.send_keys(\"Data Scientist\")\n",
    "\n",
    "search_btn=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_btn.click()\n",
    "\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "#clicking intel delhi/ncr filter\n",
    "search_btn = driver.find_element_by_xpath(\"//*[text() ='Delhi/NCR']\")\n",
    "search_btn.click()\n",
    "\n",
    "#clicking intel 3-6 Lakhs filter\n",
    "search_btn2 = driver.find_element_by_xpath(\"//*[text() ='3-6 Lakhs']\")\n",
    "search_btn2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Companies</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Country Veggie</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Ghaziabad, Bhopal, Lucknow, Kanpur, Rajkot, Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist - NLP</td>\n",
       "      <td>IRIS SOFTWARE Inc</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Delhi NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Delhi NCR, Noida, Gurgaon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                     Data Scientist   \n",
       "1                                     Data Scientist   \n",
       "2                        Senior Data Scientist - NLP   \n",
       "3  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "\n",
       "                   Companies Experience  \\\n",
       "0             Country Veggie    1-3 Yrs   \n",
       "1     IBM India Pvt. Limited    4-8 Yrs   \n",
       "2          IRIS SOFTWARE Inc    4-9 Yrs   \n",
       "3  GABA Consultancy services    0-0 Yrs   \n",
       "\n",
       "                                            Location  \n",
       "0  Ghaziabad, Bhopal, Lucknow, Kanpur, Rajkot, Be...  \n",
       "1                                   Gurgaon Gurugram  \n",
       "2                                          Delhi NCR  \n",
       "3                          Delhi NCR, Noida, Gurgaon  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "job_titles=[]\n",
    "company_name=[]\n",
    "location_list=[]\n",
    "experience_list=[]\n",
    "\n",
    "titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_titles.append(title)\n",
    "    \n",
    "job_titles[:4]\n",
    "\n",
    "companies_tags=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in companies_tags:\n",
    "    companies=i.text\n",
    "    company_name.append(companies)\n",
    "    \n",
    "company_name[:4]\n",
    "\n",
    "location_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span[1]')\n",
    "for i in location_tags:\n",
    "    location=i.text\n",
    "    location_list.append(location)\n",
    "    \n",
    "location_list[:4]\n",
    "\n",
    "experience_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span[1]')\n",
    "for i in experience_tags:\n",
    "    experience=i.text\n",
    "    experience_list.append(experience)\n",
    "    \n",
    "experience_list[:4]\n",
    "\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job_titles\n",
    "jobs['Companies']=company_name\n",
    "jobs['Experience']=experience_list\n",
    "jobs['Location']=location_list\n",
    "\n",
    "jobs[:4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.glassdoor.co.in/index.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_jobs=driver.find_element_by_id('sc.keyword')\n",
    "search_jobs.send_keys(\"Data Scientist\")\n",
    "search_loc=driver.find_element_by_xpath(\"//input[@id='sc.location']\")\n",
    "search_loc.send_keys(\"Noida\")\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Companies</th>\n",
       "      <th>Location</th>\n",
       "      <th>Days Ago</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst/ Scientist</td>\n",
       "      <td>ANI Calls India Private Limited</td>\n",
       "      <td>Noida</td>\n",
       "      <td>30d+</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst – Fresher – Data Scientist – Grad...</td>\n",
       "      <td>Structured Learning Assistance Consultants Ind...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>30d+</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>Noida</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst / Fresher / Data Scientist / Grad...</td>\n",
       "      <td>Structured Learning Assistance Consultants Ind...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>30d+</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>Emerging India Group</td>\n",
       "      <td>Noida</td>\n",
       "      <td>30d+</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Adobe</td>\n",
       "      <td>Noida</td>\n",
       "      <td>7d</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>WishFin</td>\n",
       "      <td>Noida</td>\n",
       "      <td>17d</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Kronos Incorporated</td>\n",
       "      <td>Noida</td>\n",
       "      <td>5d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>Noida</td>\n",
       "      <td>30d+</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist/Analyst</td>\n",
       "      <td>Singh RanjayKumar(Proprietor Of Zee India Co)</td>\n",
       "      <td>Noida</td>\n",
       "      <td>2d</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                            Data Analyst/ Scientist   \n",
       "1  Data Analyst – Fresher – Data Scientist – Grad...   \n",
       "2                                     Data Scientist   \n",
       "3  Data Analyst / Fresher / Data Scientist / Grad...   \n",
       "4                                                      \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                           Principal Data Scientist   \n",
       "8                              Data Scientist Intern   \n",
       "9                             Data Scientist/Analyst   \n",
       "\n",
       "                                           Companies Location Days Ago  \\\n",
       "0                    ANI Calls India Private Limited    Noida     30d+   \n",
       "1  Structured Learning Assistance Consultants Ind...    Delhi     30d+   \n",
       "2                                     Biz2Credit Inc    Noida     30d+   \n",
       "3  Structured Learning Assistance Consultants Ind...    Delhi     30d+   \n",
       "4                               Emerging India Group    Noida     30d+   \n",
       "5                                              Adobe    Noida       7d   \n",
       "6                                            WishFin    Noida      17d   \n",
       "7                                Kronos Incorporated    Noida       5d   \n",
       "8                       Salasar New Age Technologies    Noida     30d+   \n",
       "9      Singh RanjayKumar(Proprietor Of Zee India Co)    Noida       2d   \n",
       "\n",
       "   Ratings  \n",
       "0  unknown  \n",
       "1  unknown  \n",
       "2      3.7  \n",
       "3  unknown  \n",
       "4  unknown  \n",
       "5      4.4  \n",
       "6      4.0  \n",
       "7      4.3  \n",
       "8  unknown  \n",
       "9  unknown  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles=[]\n",
    "company_name=[]\n",
    "location_list=[]\n",
    "days_ago_list=[]\n",
    "rating=[]\n",
    "\n",
    "titles_tags=driver.find_elements_by_xpath(\"//a[@class='jobLink css-1rd3saf eigr9kq2']/span\")\n",
    "\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_titles.append(title)\n",
    "    \n",
    "job_titles[:4]\n",
    "\n",
    "companies_tags=driver.find_elements_by_xpath('//div[@class=\"d-flex justify-content-between align-items-start\"]/a/span')\n",
    "for i in companies_tags:\n",
    "    companies=i.text\n",
    "    company_name.append(companies)\n",
    "    \n",
    "company_name[:4]\n",
    "\n",
    "location_tags=driver.find_elements_by_xpath('//span[@class=\"pr-xxsm css-1ndif2q e1rrn5ka0\"]')\n",
    "for i in location_tags:\n",
    "    location=i.text\n",
    "    location_list.append(location)\n",
    "    \n",
    "location_list[:4]\n",
    "\n",
    "days_ago_tags=driver.find_elements_by_xpath('//div[@class=\"d-flex align-items-end pl-std css-mi55ob\"]')\n",
    "for i in days_ago_tags:\n",
    "    days_ago=i.text\n",
    "    days_ago_list.append(days_ago)\n",
    "    \n",
    "rating_tag = driver.find_elements_by_xpath(\"//div[@class='d-flex flex-column css-x75kgh e1rrn5ka3']\")\n",
    "for i in rating_tag:\n",
    "    if i.text == '':\n",
    "        rating.append(\"unknown\")\n",
    "        \n",
    "    else:\n",
    "        name3=i.text\n",
    "        rating.append(name3)\n",
    "\n",
    "\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job_titles\n",
    "jobs['Companies']=company_name\n",
    "jobs['Location']=location_list\n",
    "jobs['Days Ago']=days_ago_list\n",
    "jobs['Ratings']=rating\n",
    "\n",
    "jobs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.5: Write a python program to scrape the salary data for Data Scientist designation in Noida location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.glassdoor.co.in/Salaries/index.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding job bt different element\n",
    "search_job = driver.find_element_by_id('KeywordSearch')\n",
    "search_job.send_keys('Data Scientist')\n",
    "search_loc =  driver.find_element_by_id('LocationSearch')\n",
    "search_loc.send_keys('noida')\n",
    "\n",
    "#clicking Search button\n",
    "search_btn = driver.find_element_by_id(\"HeroSearchButton\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Number Salary</th>\n",
       "      <th>Average</th>\n",
       "      <th>Minimum</th>\n",
       "      <th>Maximum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>13 salaries</td>\n",
       "      <td>₹ 12,64,182</td>\n",
       "      <td>₹450K</td>\n",
       "      <td>₹11,630K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>12 salaries</td>\n",
       "      <td>₹ 7,30,968</td>\n",
       "      <td>₹350K</td>\n",
       "      <td>₹1,614K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>11 salaries</td>\n",
       "      <td>₹ 6,00,000</td>\n",
       "      <td>₹336K</td>\n",
       "      <td>₹1,010K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹ 9,94,055</td>\n",
       "      <td>₹577K</td>\n",
       "      <td>₹2,215K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IBM</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹ 7,39,040</td>\n",
       "      <td>₹587K</td>\n",
       "      <td>₹2,732K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹ 13,37,114</td>\n",
       "      <td>₹717K</td>\n",
       "      <td>₹1,575K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 7,80,374</td>\n",
       "      <td>₹502K</td>\n",
       "      <td>₹1,152K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>7 salaries</td>\n",
       "      <td>₹ 11,98,792</td>\n",
       "      <td>₹621K</td>\n",
       "      <td>₹1,696K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>6 salaries</td>\n",
       "      <td>₹ 10,08,143</td>\n",
       "      <td>₹793K</td>\n",
       "      <td>₹1,264K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>6 salaries</td>\n",
       "      <td>₹ 11,34,989</td>\n",
       "      <td>₹576K</td>\n",
       "      <td>₹1,500K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name Number Salary      Average Minimum   Maximum\n",
       "0                       Delhivery   13 salaries  ₹ 12,64,182   ₹450K  ₹11,630K\n",
       "1              Ericsson-Worldwide   12 salaries   ₹ 7,30,968   ₹350K   ₹1,614K\n",
       "2       Tata Consultancy Services   11 salaries   ₹ 6,00,000   ₹336K   ₹1,010K\n",
       "3                       Accenture   10 salaries   ₹ 9,94,055   ₹577K   ₹2,215K\n",
       "4                             IBM   10 salaries   ₹ 7,39,040   ₹587K   ₹2,732K\n",
       "5              UnitedHealth Group    9 salaries  ₹ 13,37,114   ₹717K   ₹1,575K\n",
       "6              Valiance Solutions    8 salaries   ₹ 7,80,374   ₹502K   ₹1,152K\n",
       "7                      Innovaccer    7 salaries  ₹ 11,98,792   ₹621K   ₹1,696K\n",
       "8  Cognizant Technology Solutions    6 salaries  ₹ 10,08,143   ₹793K   ₹1,264K\n",
       "9                     EXL Service    6 salaries  ₹ 11,34,989   ₹576K   ₹1,500K"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making empty list of all the data we need\n",
    "number=[]\n",
    "avg=[]\n",
    "company_name=[]\n",
    "min_sa=[]\n",
    "max_sa=[]\n",
    "\n",
    "#extracting required element\n",
    "company_tag = driver.find_elements_by_xpath(\"//div[@class='d-flex']/div[2]/p[2]\")\n",
    "number_tag = driver.find_elements_by_xpath(\"//div[@class='d-flex']/div[2]/p[5]\")\n",
    "avg_tag = driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']/strong\")\n",
    "min_tag = driver.find_elements_by_xpath(\"//div[@class='col-3 offset-1 d-none d-md-block']\")\n",
    "max_tag = driver.find_elements_by_xpath(\"//div[@class='col-3 offset-1 d-none d-md-block']\")\n",
    "\n",
    "\n",
    "#exctacting titles\n",
    "for i in company_tag:\n",
    "    name1=i.text\n",
    "    company_name.append(name1)\n",
    "    \n",
    "#extracting number of salaries\n",
    "for j in number_tag:\n",
    "    name2=j.text\n",
    "    number.append(name2)\n",
    "    \n",
    "#extracting Average salary\n",
    "for k in avg_tag:\n",
    "    name3=k.text\n",
    "    avg.append(name3)    \n",
    "    \n",
    "#extracting minimum salary\n",
    "for l in min_tag:\n",
    "    name4=l.text.split()[0]\n",
    "    min_sa.append(name4)\n",
    "    \n",
    "#extracting maximum salary\n",
    "for m in min_tag:\n",
    "    name5=m.text.split()[1]\n",
    "    max_sa.append(name5)\n",
    "    \n",
    "#making dataframe\n",
    "companies = pd.DataFrame({'Name':company_name,'Number Salary':number,'Average':avg,'Minimum':min_sa,'Maximum':max_sa}).head(10)\n",
    "companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.6: Scrape data of first 100 sunglasses listings on flipkart.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.flipkart.com')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding job bt different element\n",
    "search_job = driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input\")\n",
    "search_job.send_keys('sunglasses')\n",
    "\n",
    "#clicking Search button\n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Mirrored, UV Protection Round Sunglasses (Free...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹349</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EYELLUSION</td>\n",
       "      <td>Night Vision, Polarized, UV Protection, Riding...</td>\n",
       "      <td>₹344</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Royal Son</td>\n",
       "      <td>Mirrored Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹299</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wrap-around Sunglasses (Free Size)</td>\n",
       "      <td>₹830</td>\n",
       "      <td>7% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Tazzx</td>\n",
       "      <td>UV Protection Round Sunglasses (55)</td>\n",
       "      <td>₹251</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>like future</td>\n",
       "      <td>UV Protection Round Sunglasses (Free Size)</td>\n",
       "      <td>₹298</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Tazzx</td>\n",
       "      <td>UV Protection Round Sunglasses (55)</td>\n",
       "      <td>₹159</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>funglasses</td>\n",
       "      <td>UV Protection, Polarized Retro Square Sunglass...</td>\n",
       "      <td>₹149</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>shah collections</td>\n",
       "      <td>UV Protection Round Sunglasses (Free Size)</td>\n",
       "      <td>₹198</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand                                        Description  \\\n",
       "0      ROZZETTA CRAFT  Mirrored, UV Protection Round Sunglasses (Free...   \n",
       "1              PIRASO              UV Protection Aviator Sunglasses (58)   \n",
       "2          EYELLUSION  Night Vision, Polarized, UV Protection, Riding...   \n",
       "3           Royal Son           Mirrored Wayfarer Sunglasses (Free Size)   \n",
       "4            Fastrack   UV Protection Wrap-around Sunglasses (Free Size)   \n",
       "..                ...                                                ...   \n",
       "115             Tazzx                UV Protection Round Sunglasses (55)   \n",
       "116       like future         UV Protection Round Sunglasses (Free Size)   \n",
       "117             Tazzx                UV Protection Round Sunglasses (55)   \n",
       "118        funglasses  UV Protection, Polarized Retro Square Sunglass...   \n",
       "119  shah collections         UV Protection Round Sunglasses (Free Size)   \n",
       "\n",
       "    Price Discount  \n",
       "0    ₹399  72% off  \n",
       "1    ₹349  86% off  \n",
       "2    ₹344  85% off  \n",
       "3    ₹299  80% off  \n",
       "4    ₹830   7% off  \n",
       "..    ...      ...  \n",
       "115  ₹251  87% off  \n",
       "116  ₹298  75% off  \n",
       "117  ₹159  84% off  \n",
       "118  ₹149  85% off  \n",
       "119  ₹198  84% off  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "brands_list=[]\n",
    "desc_list=[]\n",
    "price_list=[]\n",
    "disc_list=[]\n",
    "\n",
    "num = np.arange(1,4)\n",
    "for page in num:\n",
    "    #extracting required element\n",
    "    brands = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    desc = driver.find_elements_by_xpath(\"//*[@class='IRpwTa' or @class='IRpwTa _2-ICcC' ]\")\n",
    "    prices = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    off_tag =  driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "\n",
    "    for i in brands:\n",
    "        brand=i.text\n",
    "        brands_list.append(brand)\n",
    "    for i in desc:\n",
    "        descs=i.text\n",
    "        desc_list.append(descs)\n",
    "    \n",
    "    for i in prices:\n",
    "        price=i.text\n",
    "        price_list.append(price)\n",
    "    \n",
    "    \n",
    "    #extracting discount\n",
    "    for l in off_tag:\n",
    "        if off_tag is not None:\n",
    "            name4=l.text\n",
    "            disc_list.append(name4)\n",
    "        else:\n",
    "            disc_list.append(\"unknown\")\n",
    "        \n",
    "    print(page)\n",
    "    driver.find_element_by_xpath(\"//*[text()='Next']\").click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "sunglasses=pd.DataFrame({})\n",
    "sunglasses['Brand']=brands_list\n",
    "sunglasses['Description']=desc_list\n",
    "sunglasses['Price']=price_list\n",
    "sunglasses['Discount']=disc_list\n",
    "sunglasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.7: Scrape 100 reviews data from flipkart.com for iphone11 phone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3QP11A&marketplace=FLIPKART')\n",
    "# clicking see all review  button\n",
    "# all_btn = driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\")\n",
    "# all_btn.click()\n",
    "\n",
    "ratings_list=[]\n",
    "desc_list=[]\n",
    "lng_des_list=[]\n",
    "num = np.arange(1,5)\n",
    "for page in num:\n",
    "    ratings = driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    desc=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    lng_des=driver.find_elements_by_xpath(\"//div[@class='\"\"']\")\n",
    "\n",
    "    for i in ratings:\n",
    "        rating=i.text\n",
    "        ratings_list.append(rating)\n",
    "    \n",
    "    for i in desc:\n",
    "        descs=i.text\n",
    "        desc_list.append(descs)\n",
    "    \n",
    "    for i in lng_des:\n",
    "        lng_desc=i.text\n",
    "        lng_des_list.append(lng_desc)\n",
    "    print(page)\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath(\"//*[text()='Next']\").click()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "num1 = np.arange(5,13)\n",
    "for page in num1:\n",
    "    ratings = driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    desc=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    lng_des=driver.find_elements_by_xpath(\"//div[@class='\"\"']\")\n",
    "\n",
    "    for i in ratings:\n",
    "        rating=i.text\n",
    "        ratings_list.append(rating)\n",
    "    \n",
    "    for i in desc:\n",
    "        descs=i.text\n",
    "        desc_list.append(descs)\n",
    "    \n",
    "    for i in lng_des:\n",
    "        lng_desc=i.text\n",
    "        lng_des_list.append(lng_desc)\n",
    "    print(page)\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath(\"//*[text()='Next']\").click()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Short Description</th>\n",
       "      <th>Long Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Battery backup is extraordinary, camera is dec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Just an awesome phone...upgraded from 6s to 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Decent product</td>\n",
       "      <td>Everything u ll like it when u use this iPhone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>I purchased the iPhone 11 a month back. I must...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Value for money product. This iphone 11 is rea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating   Short Description  \\\n",
       "0       5    Perfect product!   \n",
       "1       5       Great product   \n",
       "2       5  Highly recommended   \n",
       "3       5    Perfect product!   \n",
       "4       5           Brilliant   \n",
       "..    ...                 ...   \n",
       "95      3    Perfect product!   \n",
       "96      5           Fabulous!   \n",
       "97      5      Decent product   \n",
       "98      5           Fabulous!   \n",
       "99      4           Excellent   \n",
       "\n",
       "                                     Long Description  \n",
       "0   Amazing phone with great cameras and better ba...  \n",
       "1   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "2   iphone 11 is a very good phone to buy only if ...  \n",
       "3   It’s a must buy who is looking for an upgrade ...  \n",
       "4   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "..                                                ...  \n",
       "95  Battery backup is extraordinary, camera is dec...  \n",
       "96  Just an awesome phone...upgraded from 6s to 11...  \n",
       "97  Everything u ll like it when u use this iPhone...  \n",
       "98  I purchased the iPhone 11 a month back. I must...  \n",
       "99  Value for money product. This iphone 11 is rea...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews=pd.DataFrame({})\n",
    "reviews['Rating']=ratings_list[:117]\n",
    "reviews['Short Description']=desc_list[:117]\n",
    "reviews['Long Description']=lng_des_list[:117]\n",
    "\n",
    "reviews.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.flipkart.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#finding job bt different element\n",
    "search_job = driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input\")\n",
    "search_job.send_keys('sneakers')\n",
    "\n",
    "#clicking Search button\n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_btn.click()\n",
    "\n",
    "#Making empty list of all the data we need\n",
    "brand=[]\n",
    "dec=[]\n",
    "disc=[]\n",
    "price=[]\n",
    "\n",
    "num = np.arange(1,4)\n",
    "for page in num:\n",
    "    #extracting required element\n",
    "    brand_tag = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    desc_tag = driver.find_elements_by_xpath(\"//*[@class='IRpwTa' or @class='IRpwTa _2-ICcC' ]\")\n",
    "    price_tag = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    off_tag =  driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "\n",
    "\n",
    "    #exctacting brand\n",
    "    for i in brand_tag:\n",
    "        name1=i.text\n",
    "        brand.append(name1)\n",
    "    \n",
    "    #extracting description\n",
    "    for k in desc_tag:\n",
    "        name3=k.text\n",
    "        dec.append(name3)\n",
    "    #extracting price\n",
    "    for k in price_tag:\n",
    "        name3=k.text\n",
    "        price.append(name3)    \n",
    "    \n",
    "    #extracting discount\n",
    "    for l in off_tag:\n",
    "        if off_tag is not None:\n",
    "            name4=l.text\n",
    "            disc.append(name4)\n",
    "        else:\n",
    "            disc.append(\"unknown\")\n",
    "    print(page)\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath(\"//*[text()='Next']\").click()\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Echor</td>\n",
       "      <td>HHM Sneakers For Men</td>\n",
       "      <td>₹601</td>\n",
       "      <td>39% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Englewood</td>\n",
       "      <td>White Shoes For Men | Casual White Laceups Sho...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>168 Smart Red Lace-Ups Casuals for Men Sneaker...</td>\n",
       "      <td>₹236</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Earton</td>\n",
       "      <td>Sports and Running shoe for men (Combo pack of...</td>\n",
       "      <td>₹569</td>\n",
       "      <td>42% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Aura</td>\n",
       "      <td>Stylish and Comfortable Sneakers For Men</td>\n",
       "      <td>₹279</td>\n",
       "      <td>44% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Ontario IDP Sneakers For Men</td>\n",
       "      <td>₹1,399</td>\n",
       "      <td>53% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Creer</td>\n",
       "      <td>STYLISH Sneakers For Men</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Absolute comfort</td>\n",
       "      <td>COMBO-(2)-RWT Sneakers For Men</td>\n",
       "      <td>₹367</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>171 Smart Tan Lace-Ups Casuals for Men Sneaker...</td>\n",
       "      <td>₹236</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                                        Description  \\\n",
       "0              Echor                               HHM Sneakers For Men   \n",
       "1          Englewood  White Shoes For Men | Casual White Laceups Sho...   \n",
       "2             Chevit  168 Smart Red Lace-Ups Casuals for Men Sneaker...   \n",
       "3             Earton  Sports and Running shoe for men (Combo pack of...   \n",
       "4       Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "..               ...                                                ...   \n",
       "75              Aura           Stylish and Comfortable Sneakers For Men   \n",
       "76              Puma                       Ontario IDP Sneakers For Men   \n",
       "77             Creer                           STYLISH Sneakers For Men   \n",
       "78  Absolute comfort                     COMBO-(2)-RWT Sneakers For Men   \n",
       "79            Chevit  171 Smart Tan Lace-Ups Casuals for Men Sneaker...   \n",
       "\n",
       "     Price Discount  \n",
       "0     ₹601  39% off  \n",
       "1     ₹499  66% off  \n",
       "2     ₹236  52% off  \n",
       "3     ₹569  42% off  \n",
       "4     ₹499  50% off  \n",
       "..     ...      ...  \n",
       "75    ₹279  44% off  \n",
       "76  ₹1,399  53% off  \n",
       "77    ₹398  60% off  \n",
       "78    ₹367  63% off  \n",
       "79    ₹236  52% off  \n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making dataframe\n",
    "sneakers = pd.DataFrame({'Name':brand,'Description':dec,'Price':price,'Discount':disc}).head(100)\n",
    "sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9: Go to the link - https://www.myntra.com/shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking price filter\n",
    "search_btn = driver.find_element_by_xpath(\"//ul[@class='price-list']/li[2]\").click()\n",
    "search_btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking black filter\n",
    "search_btn = driver.find_element_by_xpath(\"//*[text() ='Black']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men HYBRID NETFIT Running Shoe</td>\n",
       "      <td>6599Rs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>PEGASUS FLYEASE Running Shoes</td>\n",
       "      <td>7996Rs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DIESEL</td>\n",
       "      <td>Men DANNY LC Sneakers</td>\n",
       "      <td>9093Rs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Basketball</td>\n",
       "      <td>12495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men SOLAR DRIVE 19 M Running</td>\n",
       "      <td>8399Rs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>6990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Charged Rogue 2 Wide 2E Shoes</td>\n",
       "      <td>7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men Charged Escape 3 Evo</td>\n",
       "      <td>8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Xtep</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>9349Rs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Xtep</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>9349Rs.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name                        Description    Price\n",
       "0           Puma     Men HYBRID NETFIT Running Shoe  6599Rs.\n",
       "1           Nike      PEGASUS FLYEASE Running Shoes  7996Rs.\n",
       "2         DIESEL              Men DANNY LC Sneakers  9093Rs.\n",
       "3           Nike        Men JORDAN DELTA Basketball    12495\n",
       "4         ADIDAS       Men SOLAR DRIVE 19 M Running  8399Rs.\n",
       "..           ...                                ...      ...\n",
       "95         Ruosh  Men Solid Leather Formal Slip-Ons     6990\n",
       "96  UNDER ARMOUR      Charged Rogue 2 Wide 2E Shoes     7999\n",
       "97  UNDER ARMOUR           Men Charged Escape 3 Evo     8999\n",
       "98          Xtep                  Men Running Shoes  9349Rs.\n",
       "99          Xtep                  Men Running Shoes  9349Rs.\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making empty list of all the data we need\n",
    "brand=[]\n",
    "dec=[]\n",
    "price=[]\n",
    "\n",
    "num = np.arange(1,4)\n",
    "for page in num:\n",
    "    #extracting required element\n",
    "    brand_tag = driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "    desc_tag = driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "    price_tag = driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "\n",
    "\n",
    "    #exctacting brand\n",
    "    for i in brand_tag:\n",
    "        name1=i.text\n",
    "        brand.append(name1)\n",
    "    \n",
    "    #extracting description\n",
    "    for k in desc_tag:\n",
    "        name3=k.text\n",
    "        dec.append(name3)\n",
    "    #extracting price\n",
    "    for k in price_tag:\n",
    "        name3=k.text.split()[1]\n",
    "        price.append(name3)    \n",
    "        \n",
    "    print(page)\n",
    "    driver.find_element_by_xpath(\"//li[@class='pagination-next']\").click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    \n",
    "\n",
    "#making dataframe\n",
    "products = pd.DataFrame({'Name':brand,'Description':dec,'Price':price}).head(100)\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.amazon.in/')\n",
    "\n",
    "\n",
    "#finding job bt different element\n",
    "search_job = driver.find_element_by_id('twotabsearchtextbox')\n",
    "search_job.send_keys('laptop')\n",
    "\n",
    "#clicking Search button\n",
    "search_btn = driver.find_element_by_id(\"nav-search-submit-button\")\n",
    "search_btn.click()\n",
    "\n",
    "#clicking intel i7 filter\n",
    "search_btn = driver.find_element_by_xpath(\"//*[text() ='Intel Core i7']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Name         Price  \\\n",
      "0  Lenovo Yoga S940 Intel Core i7 10th Gen 14\" UH...   2,23,890.00   \n",
      "1  Mi Notebook Horizon Edition 14 Intel Core i5-1...     50,999.00   \n",
      "2  HP Pavilion x360 Touchscreen 2-in-1 FHD 14-inc...     92,418.00   \n",
      "3  HP 14 Thin & Light 14-inch FHD Laptop (11th Ge...     90,079.50   \n",
      "4  Lenovo IdeaPad Gaming 3i 10th Gen Intel Core i...   1,15,390.00   \n",
      "5  HP Pavilion x360 Core i7 8th Gen 14-inch Touch...     98,242.00   \n",
      "6  Dell Alienware m15(R3) 15.6-inch FHD Gaming La...   2,10,000.00   \n",
      "7  (Renewed) Dell Latitude E6420 14 Inch Laptop (...             -   \n",
      "8  Lenovo Yoga S740 Intel Core i7 10th Gen 14 inc...   1,60,890.00   \n",
      "9  Dell G3 3500 Gaming 15.6inch 120hz FHD Display...     93,971.00   \n",
      "\n",
      "               Rating  \n",
      "0  3.3 out of 5 stars  \n",
      "1  4.2 out of 5 stars  \n",
      "2  3.5 out of 5 stars  \n",
      "3  4.0 out of 5 stars  \n",
      "4  3.8 out of 5 stars  \n",
      "5  4.1 out of 5 stars  \n",
      "6  2.7 out of 5 stars  \n",
      "7  1.0 out of 5 stars  \n",
      "8  3.3 out of 5 stars  \n",
      "9  4.0 out of 5 stars  \n"
     ]
    }
   ],
   "source": [
    "# Function Definition\n",
    "def amazon_mob(url):\n",
    "    urls = []\n",
    "    name=[]\n",
    "    price=[]\n",
    "    rating=[]\n",
    "  \n",
    "    driver.get(url)\n",
    "    soup= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    prod_urls = soup.find_all('a', attrs ={'class':'a-link-normal a-text-normal'})\n",
    "    for prod in prod_urls:\n",
    "        urls.append('https://www.amazon.in'+prod.get('href'))\n",
    "    \n",
    "    #loop to scrap required details from each mobile page\n",
    "    for url in urls[:10]:\n",
    "        driver.get(url)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        n = soup.find('h1',attrs={'id':'title'})\n",
    "        if n is not None:\n",
    "            name.append(n.find('span').text.replace('\\n',''))\n",
    "        else:\n",
    "            name.append('-')\n",
    "        rat = soup.find('div', attrs = {'id':'averageCustomerReviews'})\n",
    "        if rat is not None:\n",
    "            rating.append(rat.find('i').find('span').text)\n",
    "        else:\n",
    "            rating.append('-')\n",
    "        p = soup.find('span', attrs = {'class':'a-size-medium a-color-price priceBlockDealPriceString'})\n",
    "        if p is not None:\n",
    "            price.append(p.text[2:])\n",
    "        else:\n",
    "            p = soup.find('div', attrs = {'id':'price'})\n",
    "            if p is not None:\n",
    "                price.append(p.find('span').text[2:])\n",
    "            else:\n",
    "                price.append('-')\n",
    "      \n",
    "    mob_df = df=pd.DataFrame({'Name':name,\n",
    "                              'Price':price,\n",
    "                              'Rating':rating})\n",
    "    print(mob_df[:10])\n",
    "    \n",
    "    \n",
    "# Calling Function\n",
    "amazon_mob('https://www.amazon.in/s?k=laptop&rh=n%3A1375424031%2Cp_n_feature_thirteen_browse-bin%3A12598163031&dc&qid=1613487824&rnid=12598141031&ref=sr_nr_p_n_feature_thirteen_browse-bin_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
